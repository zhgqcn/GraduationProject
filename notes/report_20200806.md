## 设想

1. CPU训练
2. BatchSize 的调整训练
3. 单通道不复制
4. 减少数据集
5. 加载模型，继续训练



### 尝试CPU训练

我自己有一台4G的云主机，所以进行了配置，在4G内存的基础上，配置8G的Swap虚拟内存，保存数据加载不会out of Memory.

![Snipaste_2020-08-06_07-26-38](https://tvax4.sinaimg.cn/large/005tpOh1gy1ghgqkzhkwmj30kj025q36.jpg)

但是，我只用了16张作为数据集，16张作为测试集，训练一天下来仅有5 epochs，之后也会停滞不前。

在数据较多时，根本训练不了

### BatchSize调整训练

1. 在显存空间足够大时，尽量增大BatchSize可以减少训练的时间，经过多次尝试，batchSize = 8 是 Colab 中可以运行的最大batch。

2. 为了增多训练的次数，使得loss能够更佳，我把源代码每次都进行val测试修改为每10epochs才进行一次val，这样子可以时间尽可能少的情况下，进行尽可能多的训练迭代

![Snipaste_2020-08-06_07-37-02](https://tva3.sinaimg.cn/large/005tpOh1gy1ghgqvhvut2j31fc0iq43k.jpg)





**目前已经调试通过了训练10代之后才进行val的代码**，但是colab太不稳定，训练容易断开，运气好点训练10小时也才60代（训练集1152张）

学长的训练是直接用一百多张作为训练集的，所以我们的训练集差了10倍左右，为了能够训练迭代更多次数，接下来我也减少训练集。



